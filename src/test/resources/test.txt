
STRINGDECODE('以redis的数据持久化就显得尤为重要，在redis当中，提供了两种数据持久化的方式，分别为RDB以及AOF，且redis默认开启的数据持久化方式为RDB方式。\n\n#### 7.3.1、rdb(保存快照)  \nRedis会定期保存数据快照至一个rbd文件中，并在启动时自动加载rdb文件，恢复之前保存的数据。可以在配置文件中配置Redis进行快照保存的时机：  \nsave [seconds][changes]  \n意为在[seconds]秒内如果发生了[changes]次数据修改，则进行一次RDB快照保存，例如：`save 60 100`  \n会让Redis每60秒检查一次数据变更情况，如果发生了100次或以上的数据变更，则进行RDB快照保存。\n\n**优点**  \n​1. 对性能影响最小。Redis在保存RDB快照时会fork出子进程进行，几乎不影响Redis处理客户端请求的效率。  \n​2. 每次快照会生成一个完整的数据快照文件，所以可以辅以其他手段保存多个时间点的快照（例如把每天0点的快照备份至其他存储媒介中），作为非常可靠的灾难恢复手段。  \n3. 使用RDB文件进行数据恢复比使用AOF要快很多。  \n\n**缺点**  \n1. 快照是定期生成的，所以在Redis crash时或多或少会丢失一部分数据。\n2. 如果数据集非常大且CPU不够强（比如单核CPU），Redis在fork子进程时可能会消耗相对较长的时间，影响Redis对外提供服务的能力。\n\n#### 7.3.2、AOF（预写日志）\n采用AOF持久方式时，Redis会把每一个写请求都记录在一个日志文件里。Redis每次启动时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新。AOF默认是关闭的，如要开启，进行如下配置：`appendonly yes`  \n\nAOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定：  \n**appendfsync no**：不进行fsync，将flush文件的时机交给OS决定，速度最快；  \n**appendfsync always**：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢；  \n**appendfsync everysec**：折中的做法，交由后台线程每秒fsync一次；    \n\n**优点**  \n1. 最安全，在启用appendfsync always时，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据\n2. AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况，也可以使用redis-check-aof工具轻松修复。\n3. AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。\n\n**缺点**  \n1. AOF文件通常比RDB文件更大\n2. 性能消耗比RDB高\n3. 数据恢复速度比RDB慢\n\n<font color=red>记忆：  \nRDB 保存快照：定期保存快照 启动加载 默认开启  \nsave 60 100  \n优点：性能 完整 快  \n缺点：性能 丢失  \n\nAOF 预写日志：记录所有写请求 启动依序执行 默认关闭  \nappendonly yes  \nappendfsync everysec  \n优点：断电 不丢失 易读可改  \n缺点：性能 大 慢  \n</font>\n\n注：RDB与AOF同时开启，默认无脑加载AOF的配置文件。\n\n### 7.4、缓存雪崩\n#### 7.4.1、我们为什么要用缓存(Redis)  \n![](http://mediocrepeople.tpddns.cn:9999/upload/2020/4/1582259581847.png)  \n\n#### 7.4.2、如果缓存挂了呢  \n![](http://mediocrepeople.tpddns.cn:9999/upload/2020/4/1582259706728.png)  \n\n#### 7.4.3、雪崩场景\n* Redis挂掉了，请求全部走数据库。\n* 对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。\n\n缓存雪崩如果发生了，很可能就把我们的数据库搞垮，导致整个服务瘫痪！\n\n#### 7.4.4、如何解决缓存雪崩\n* 对于“Redis挂掉了，请求全部走数据库”这种情况\n  * 事发前：实现Redis的高可用(**主从架构+Sentinel（哨兵） 或者Redis Cluster（集群）)，尽量避免Redis挂掉这种情况发生**。\n  * 事发中：万一Redis真的挂了，我们可以设置**本地缓存**(ehcache)+**限流**(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)\n  * 事发后：**redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据**。\n* 对于“对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。”这种情况\n  * 在缓存的时候给**过期时间加上一个随机值**，这样就会大幅度的减少缓存在同一时间过期。\n\n### 7.5、缓存穿透\n#### 7.5.1、什么是缓存穿透\n缓存穿透是指查询一个一定不存在的数据。由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。  \n\n比如，我们有一张数据库表，ID都是从1开始的(正数)。但是可能有黑**客想把我的数据库搞垮**，每次请求的ID都是**负数**。这会导致我的缓存就没用了，请求全部都找数据库去了，但数据库也没有这个值啊，所以每次都返回空出去。  \n![](http://mediocrepeople.tpddns.cn:9999/upload/2020/4/1582260211360.png)  \n**缓存穿透如果发生了，也可能把我们的数据库搞垮，导致整个服务瘫痪！**  \n\n#### 7.5.2、如何解决缓存穿透\n1. 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用**布隆过滤器(BloomFilter)或者压缩filter提前拦截**，不合法就**不让这个请求到数据库层**！  \n2. 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存**里边去。下次再请求的时候，就可以从缓存里边获取了。  \n\n### 7.6、思考你的项目中Redis的使用\n* 用到Redis了吗？嗯\n* 都用到哪些数据结构？string,hash,list,set,zset\n* 存了哪些数据？数据量多大，需要使用哪种集群模式（主从同步(从节点高可用)，哨兵(sentinel)模式(主节点高可用)，集群(cluster)模式）  \n* 有数据持久化的方案吗？有，aof\n* redis的key到期，是立马进行删除吗？删除策略：1.立即删除，2.定时删除，3.惰性删除，redis是后2种一起使用。\n\n来自网络：高并发Redis不会丢数据，除非是客户端等待超时，这个并不是Redis的问题，Redis丢数据除非是服务中断，比如重启。  \n我经历过的Redis问题，大概如下：  \n- 避免灾难性或消耗性能的语句（驱动层封闭，禁用如下指令）flushall 、keys、monitor（降低50%性能）\n- 单线程机制，避免对单个key的高并发读取（业务层做内存缓存）\n- 缓存服务建议关闭持久化，fork出的子进程会卡住主进程，导致瞬间的访问超时\n- 需要aof的机器，建议预留一半内存，防止内存交换，aof还要关注硬盘空间，避免不足导致崩溃\n- 因为Redis占用大内存，如果服务器有其它进程内存不足，可能导致系统杀死Redis以释放内存\n\n\n## 8、kafka\n### 8.1、kafka介绍\nkafka是最初由linkedin公司开发的，使用scala语言编写，kafka是一个分布式，分区的，多副本的，多订阅者的消息队列系统。\n\n### 8.2、kafka相比其他消息队列的优势  \n常见的消息队列：RabbitMQ，Redis ，zeroMQ ,ActiveMQ  \n\n**kafka的优势**：  <font color=red>记忆：可靠可扩展，持久性能快</font>  \n* 可靠：分布式、分区、副本和容错。\n* 可扩展：集群轻松缩放，无需停机。\n* 持久：使用分布式提交日志，消息会尽可快速的能保存在磁盘上，因此它是持久的。 \n* 性能：对于发布和订阅消息都具有高吞吐量。即使存储了许多TB的消息，也保持稳定的性能。 \n* 快：处理速度快，保证零停机和零数据丢失。\n\n### 8.3、kafka的术语\n![](http://mediocrepeople.tpddns.cn:9999/upload/2020/4/1582261590413.png)\n\n#### 8.3.1、kafka中的术语名词\n- **Broker**：kafka集群中包含一个或者多个服务实例，这种服务实例被称为Broker\n- **Topic**：每条发布到kafka集群的消息都有一个类别，这个类别就叫做Topic \n- **Partition**：Partition是一个物理上的概念，每个Topic包含一个或者多个Partition \n- **Producer**：负责发布消息到kafka的Broker中。\n- **Consumer**：消息消费者,向kafka的broker中读取消息的客户端\n- **Consumer Group**：每一个Consumer属于一个特定的Con'), NULL);

